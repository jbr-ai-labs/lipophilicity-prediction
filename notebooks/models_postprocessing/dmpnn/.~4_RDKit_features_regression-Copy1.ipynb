{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descriptastorus.descriptors import rdNormalizedDescriptors\n",
    "from rdkit import Chem\n",
    "import logging\n",
    "\n",
    "# make the normalized descriptor generator\n",
    "generator = rdNormalizedDescriptors.RDKit2DNormalized()\n",
    "generator.columns # list of tuples:  (descriptor_name, numpytype) ...\n",
    "\n",
    "# features = generator.process(smiles)\n",
    "# features[0] is True/False if the smiles could be processed correcty\n",
    "# features[1:] are the normalized descriptors as described in generator.columns\n",
    "\n",
    "# example for converting a smiles string into the values\n",
    "def rdkit_2d_normalized_features(smiles: str):\n",
    "    # n.b. the first element is true/false if the descriptors were properly computed\n",
    "    results = generator.process(smiles)\n",
    "    processed, features = results[0], results[1:]\n",
    "    if processed is None:\n",
    "       logging.warning(\"Unable to process smiles %s\", smiles)\n",
    "    # if processed is None, the features are are default values for the type\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_COLUMN = 'Absolute Error'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "VALUE_COLUMN = 'logP'\n",
    "PREDS_COLUMN = 'logP_pred'\n",
    "\n",
    "DATASET_INPUT_PATH = '../../../data/3_final_data/split_data'\n",
    "\n",
    "DATASET_OUTPUT_PATH = '../../../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATASET_INPUT_PATH, 'logp_wo_averaging_train.csv'))\n",
    "val_data = pd.read_csv(os.path.join(DATASET_INPUT_PATH, 'logp_wo_averaging_validation.csv'))\n",
    "test_data = pd.read_csv(os.path.join(DATASET_INPUT_PATH, 'logp_wo_averaging_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_dataframe(df):\n",
    "    import numpy as np\n",
    "    rdkit_table = []\n",
    "    features_names = [gen[0] for gen in generator.columns]\n",
    "    smiles_index_dict = {}\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        smiles = df.iloc[i][SMILES_COLUMN]\n",
    "        logP = df.iloc[i][VALUE_COLUMN]\n",
    "        features = {features_names[j]:feature for j,feature in enumerate(rdkit_2d_normalized_features(smiles))}\n",
    "        features[SMILES_COLUMN] = smiles\n",
    "        features[VALUE_COLUMN] = logP\n",
    "        rdkit_table.append(features)\n",
    "        smiles_index_dict[smiles]=i\n",
    "    rdkit_features = pd.DataFrame(rdkit_table)\n",
    "    return rdkit_features, smiles_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9643/9643 [20:42<00:00,  7.76it/s]\n",
      "100%|██████████| 2067/2067 [04:23<00:00,  7.85it/s]\n",
      "100%|██████████| 2067/2067 [04:27<00:00,  7.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_rdkit, train_smiles_dict = create_feature_dataframe(train_data)\n",
    "val_data_rdkit, val_smiles_dict = create_feature_dataframe(val_data)\n",
    "test_data_rdkit, test_smiles_dict = create_feature_dataframe(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_data_rdkit.to_csv(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_train_drkit_feat.csv'))\n",
    "with open(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_train_smiles_dict.json'), 'w') as f:\n",
    "    json.dump(train_smiles_dict, f)\n",
    "val_data_rdkit.to_csv(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_val_drkit_feat.csv'))\n",
    "with open(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_val_smiles_dict.json'), 'w') as f:\n",
    "    json.dump(val_smiles_dict, f)\n",
    "test_data_rdkit.to_csv(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_test_drkit_feat.csv'))\n",
    "with open(os.path.join(DATASET_OUTPUT_PATH,'logp_wo_averaging_test_smiles_dict.json'), 'w') as f:\n",
    "    json.dump(test_smiles_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_COLUMN = 'logP'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "\n",
    "DATA_PATH = '../../../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_train_drkit_feat.csv'), index_col=0)\n",
    "val_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_val_drkit_feat.csv'), index_col=0)\n",
    "test_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_test_drkit_feat.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[VALUE_COLUMN]\n",
    "X_train = train_data.drop([VALUE_COLUMN, SMILES_COLUMN], axis = 1)\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "y_val = val_data[VALUE_COLUMN]\n",
    "X_val = val_data.drop([VALUE_COLUMN, SMILES_COLUMN], axis = 1)\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "\n",
    "y_test = test_data[VALUE_COLUMN]\n",
    "X_test = test_data.drop([VALUE_COLUMN, SMILES_COLUMN], axis = 1)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators = 100, max_depth = 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid RMSE = 0.550378750673703\n",
      "Valid R2-score is 0.9101585772785692\n",
      "Test RMSE = 0.5765899578624547\n",
      "Test R2-score is 0.9012773315417384\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds, squared=False))\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds, squared=False))\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['feature importance', 'feature name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature importance'] = feature_importance\n",
    "df['feature name'] = features\n",
    "df_20_most_important = df.sort_values(by='feature importance', ascending = False)[:20]\n",
    "with open(os.path.join(DATA_PATH,'experiments_result'),'w') as f:\n",
    "    f.write(df_20_most_important.reset_index(drop=True).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = MLPRegressor(random_state=10, max_iter=100, warm_start=True, early_stopping = True, solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alisa.Alenicheva/anaconda3/envs/chemprop/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, max_iter=100, random_state=10, solver='lbfgs',\n",
       "             warm_start=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = regr.predict(X_test_scaled)\n",
    "val_preds = regr.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid RMSE = 0.5670377404502589\n",
      "Valid R2-score is 0.9046375862326349\n",
      "Test RMSE = 0.5642646297928993\n",
      "Test R2-score is 0.9054528606765462\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds, squared=False))\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds, squared=False))\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost without MolLogP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUE_COLUMN = 'logP'\n",
    "SMILES_COLUMN = 'smiles'\n",
    "\n",
    "DATA_PATH = '../../../data/raw/baselines/dmpnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_train_drkit_feat.csv'), index_col=0)\n",
    "val_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_val_drkit_feat.csv'), index_col=0)\n",
    "test_data = pd.read_csv(os.path.join(DATA_PATH, 'logp_wo_averaging_test_drkit_feat.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[VALUE_COLUMN]\n",
    "X_train = train_data.drop([VALUE_COLUMN, SMILES_COLUMN, 'MolLogP'], axis = 1)\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "y_val = val_data[VALUE_COLUMN]\n",
    "X_val = val_data.drop([VALUE_COLUMN, SMILES_COLUMN, 'MolLogP'], axis = 1)\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "\n",
    "y_test = test_data[VALUE_COLUMN]\n",
    "X_test = test_data.drop([VALUE_COLUMN, SMILES_COLUMN, 'MolLogP'], axis = 1)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators = 100, max_depth = 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mol/anaconda3/envs/jtree/lib/python2.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/mol/anaconda3/envs/jtree/lib/python2.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "val_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Valid RMSE =', 0.5891643504760782)\n",
      "Valid R2-score is 0.897050029756\n",
      "('Test RMSE =', 0.5829575142928344)\n",
      "Test R2-score is 0.89908480897\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid RMSE =\", mean_squared_error(y_val, val_preds)**0.5)\n",
    "print(\"Valid R2-score is {0}\".format(r2_score(y_val, val_preds)))\n",
    "\n",
    "print(\"Test RMSE =\", mean_squared_error(y_test, test_preds)**0.5)\n",
    "print(\"Test R2-score is {0}\".format(r2_score(y_test, test_preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['feature importance', 'feature name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature importance'] = feature_importance\n",
    "df['feature name'] = features\n",
    "df_20_most_important = df.sort_values(by='feature importance', ascending = False)[:20]\n",
    "# with open(os.path.join(DATA_PATH,'experiments_result'),'w') as f:\n",
    "#     f.write(df_20_most_important.reset_index(drop=True).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0 | 0.13547863 | PEOE_VSA6 |\n",
      "| 1 | 0.08802548 | fr_benzene |\n",
      "| 2 | 0.056294214 | NHOHCount |\n",
      "| 3 | 0.04401501 | PEOE_VSA7 |\n",
      "| 4 | 0.043028124 | fr_alkyl_halide |\n",
      "| 5 | 0.03891857 | NumHDonors |\n",
      "| 6 | 0.0365785 | NumAromaticCarbocycles |\n",
      "| 7 | 0.022730295 | fr_Al_OH_noTert |\n",
      "| 8 | 0.019696752 | LabuteASA |\n",
      "| 9 | 0.015776157 | fr_halogen |\n",
      "| 10 | 0.015054731 | RingCount |\n",
      "| 11 | 0.014066192 | fr_Al_COO |\n",
      "| 12 | 0.013386708 | MolWt |\n",
      "| 13 | 0.010992395 | NumAliphaticCarbocycles |\n",
      "| 14 | 0.010782038 | VSA_EState7 |\n",
      "| 15 | 0.010725621 | VSA_EState10 |\n",
      "| 16 | 0.010548814 | NumAromaticRings |\n",
      "| 17 | 0.009862682 | SMR_VSA9 |\n",
      "| 18 | 0.008671275 | SMR_VSA7 |\n",
      "| 19 | 0.008569112 | Chi0v |\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_20_most_important)):\n",
    "    print '|', i, '|', df_20_most_important.iloc[i]['feature importance'], '|', df_20_most_important.iloc[i]['feature name'], '|'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 10, 20, 50],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100, 200, 500, 1000]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(np.concatenate((X_train, X_val), axis=0),\n",
    "         np.concatenate((y_train, y_val), axis=0))\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jtree] *",
   "language": "python",
   "name": "conda-env-jtree-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
